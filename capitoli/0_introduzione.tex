\chapter{Introduzione}
\label{chap:introduzione}
L'ottimizzazione delle prestazioni degli algoritmi di apprendimento automatico è una sfida da sempre presente nella ricerca scientifica e nello sviluppo delle tecnologie basate sull'intelligenza artificiale.

Lo studio e l'utilizzo di modelli efficienti è di particolare importanza in tutti quegli scenari caratterizzati da una scarsità di risorse di calcolo o di memorizzazione.
Se è pur vero che le capacità e la disponibilità dell'hardware sono storicamente da sempre in crescita, è vero anche che permangono (e anzi aumentano) scenari in cui la disponibilità di risorse non è scontata, e per cui l'incremento di tali capacità non è fattibile o conveniente.
Si pensi, per esempio, a tutti quegli oggetti di uso quotidiano ormai dotati di computer di bordo, dagli \emph{smartwatch} ai termostati di casa, la gamma di dispositivi per cui si potrebbe sviluppare ed eseguire un algoritmo intelligente è molto vasta e in crescita.

Tra le metodologie di apprendimento automatico più utilizzate, le \emph{support vector machine} (SVM) si sono dimostrate estremamente efficaci nella risoluzione di problemi di classificazione e regressione. 
Tuttavia, per problemi con grandi quantità di dati, i modelli SVM utilizzano un grande numero di \emph{vettori di supporto} (un sottoinsieme di dati di addestramento) per definire una superficie di separazione. 
Questa caratteristica rende i modelli SVM in fase di predizione onerosi in termini di risorse, sia di tempo che di spazio.

Questa tesi si pone l'obiettivo di definire, implementare e valutare sperimentalmente una nuova procedura di addestramento supervisionato per produrre modelli SVM efficienti in grado di utilizzare un numero limitato di vettori di supporto.
In particolare, il lavoro si concentra su problemi di classificazione binaria, introducendo una procedura di addestramento che consente di impostare \emph{a priori} una quantità massima di vettori di supporto.
Nella fase sperimentale si prova a quantificare il guadagno ottenuto in termini di spazio e l'eventuale perdita di accuratezza nelle previsioni rispetto a un modello SVM classico senza nessuna strategia di contenimento del numero di vettori di supporto.

La tesi è organizzata come segue: nel~\Cref{chap:AI_ML} si introduce il campo dell'apprendimento automatico, descrivendone i problemi tipici e alcuni noti approcci per risolverli; nel~\Cref{chap:SVC} si introducono brevemente i \emph{metodi kernel} e si descrivono in dettaglio i modelli \emph{support vector machine}, in particolare per problemi di classificazione; nel~\Cref{chap:sparse_svc} si espone un'analisi della letteratura relativa all'addestramento di modelli SVM parsimoniosi, per poi descrivere la proposta originale di questa tesi, la modellazione \emph{budgeted SVC}; nel~\Cref{chap:esperimenti} si descrivono gli esperimenti effettuati; si conclude infine con una discussione dei risultati ottenuti e dei possibili sviluppi futuri.