\chapter{Conclusioni e sviluppi futuri}
\label{chap:conclusioni}
Lo studio di algoritmi di apprendimento automatico in grado di produrre modelli efficienti in spazio e calcolo è interessante per diversi motivi. 
In ambienti caratterizzati da una scarsità di risorse, utilizzare modelli di dimensioni ridotte potrebbe essere una necessità.
In genere, un modello che richiede meno spazio e meno risorse di calcolo rispetto a un modello tradizionale consuma anche meno energia. Questa caratteristica potrebbe essere fondamentale nel caso di dispositivi alimentati a batteria e potrebbe comunque essere apprezzata nel caso di macchine tradizionali. 

I modelli SVM sono stati utilizzati negli anni per risolvere diversi problemi, esibendo in molti casi prestazioni competitive. Nella formulazione classica non sono però adatti a contesti con limitate risorse di memorizzazione e calcolo.

In questa tesi è stata analizzata la proposta \emph{budgeted SVC}, che consente di addestrare classificatori binari con un ristretto numero di vettori di supporto.
Gli esperimenti effettuati su diversi \emph{dataset} sintetici evidenziano come \emph{budgeted SVC} sia promettente. 
Le motivazioni sono esposte nell'elenco seguente.
\begin{itemize}
    \item Per alcuni \emph{dataset} identificati come facili, per cui le metriche di complessità F1 e F1v hanno valori bassi, la riduzione in termini di spazio può essere significativa e non penalizzante in termini di accuratezza.
    \item Per altri \emph{dataset} identificati come difficili, per cui le metriche di complessità F1 e F1v hanno valori alti, l'accuratezza subisce un peggioramento significativo al diminuire del \emph{budget}, fino al punto in cui per riduzioni importanti l'accuratezza ritorna a essere buona. Tuttavia, per i modelli peggiori le soluzioni restituite dal risolutore non sono ottime.
    \item Esprimendo il \emph{budget} come percentuale della dimensione del \emph{dataset}, si nota come valori tra il $5\%$ ed il $7\%$ della dimensione del \emph{dataset} possano essere delle buone scelte per risparmiare spazio senza sacrificare troppo in termini di accuratezza.
\end{itemize}

Gli esperimenti effettuati su \emph{dataset} di terze parti sono anche più promettenti dei precedenti risultati:
\begin{itemize}
    \item utilizzando la strategia 1, tutti i modelli con \emph{budget} mostrano un'accuratezza pari o leggermente inferiore rispetto all'accuratezza del corrispettivo modello classico;
    \item utilizzando la strategia 2, superato un certo valore di \emph{budget} soglia, la perdita in accuratezza risulta proporzionale alla riduzione di \emph{budget}.
\end{itemize}

Il confronto con altri metodi, utilizzando la strategia 1, evidenzia come \emph{budgeted SVC} sia in alcuni casi competitivo su \emph{dataset} semplici ma come sia invece maggiormente sensibile alle riduzioni di \emph{budget} su \emph{dataset} complessi.
Dai risultati ottenuti utilizzando la strategia 2, si nota che gli altri metodi considerati, NSSVM e BSGD SVM,  producono in genere modelli più accurati per valori di \emph{budget} minimi, tra l'$1\%$ e il $5\%$ della dimensione del \emph{dataset} di addestramento.

Per risparmiare ulteriore spazio nella memorizzazione di un modello SVC, anche nella formulazione classica, è stata proposta una procedura di memorizzazione compressa.
Relativamente ai modelli prodotti, si evidenza come questa rappresentazione consenta in parecchi casi una riduzione significativa dello spazio richiesto per memorizzare il modello.

Nonostante i risultati ottenuti siano un buon punto di partenza, la formulazione \emph{budgeted SVC} potrebbe essere studiata ulteriormente, cercando di espandere, migliorare o chiarire alcuni aspetti, elencati di seguito.
\begin{itemize}
    % \item Si potrebbe verificare se la variabilità ottenuta su diversi \emph{dataset} generati con gli stessi parametri sia effettivamente dovuta al fatto che il risolutore non fornisca una soluzione ottima. 
    \item Si potrebbero utilizzare \emph{dataset} sintetici di dimensione maggiore e/o \emph{dataset} con un più alto numero di attributi. Si potrebbero utilizzare ulteriori \emph{dataset} di terze parti con caratteristiche diverse rispetto a quelli già considerati.
    \item Si potrebbero incorporare delle proposte presentate in letteratura, per esempio per limitare l'effetto del rumore o per rendere il problema trattabile con altri metodi risolutivi.
    \item Si potrebbe investigare un'eventuale relazione tra \emph{budget} e rumore, per capire se una quantità molto stringente di \emph{budget} corrisponda ad una maggior robustezza rispetto a dati erroneamente etichettati.
\end{itemize}

